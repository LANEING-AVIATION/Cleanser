[
  {
    "groupId": "model_inference",
    "title": "Model inference settings",
    "fields": [
      {
        "type": "String",
        "label": "Conda environment name:",
        "info": "Name of the conda environment to activate in WSL.",
        "replaceToken": "phi-3-env",
        "defaultValue": "phi-3-env"
      },
      {
        "type": "String",
        "label": "Inference prompt template:",
        "info": "Prompt template used at inference time, make sure it matches the finetuned version.",
        "replaceToken": "<|user|>\n{}<|end|>\n<|assistant|>",
        "defaultValue": "<|user|>\\n{}<|end|>\\n<|assistant|>"
      }
    ]
  },
  {
    "groupId": "data_configs",
    "title": "Data settings",
    "fields": [
      {
        "type": "String",
        "label": "Dataset name:",
        "info": "Dataset to train the model from a local file.",
        "replaceToken": "dataset/dataset-classification.json",
        "optionValues": [
          "dataset/dataset-classification.json"
        ],
        "defaultValue": "dataset/dataset-classification.json"
      },
      {
        "type": "String",
        "label": "Training split:",
        "info": "Training split name for your dataset.",
        "replaceToken": "train",
        "defaultValue": "train"
      },
      {
        "type": "String",
        "label": "Dataset type:",
        "replaceToken": "corpus",
        "defaultValue": "corpus"
      },
      {
        "type": "String",
        "isArray": true,
        "label": "Text columns:",
        "info": "Columns that match your dataset to populate the training prompt.",
        "replaceToken": "[
  "phrase",
  "tone"
]",
        "defaultValue": [
          "phrase",
          "tone"
        ]
      },
      {
        "type": "String",
        "label": "Text template:",
        "info": "Prompt template to finetune the model, it uses replacement from with the columns.",
        "replaceToken": "<|user|>\n{phrase}<|end|>\n<|assistant|>\n{tone}<|end|>",
        "defaultValue": "<|user|>\\n{phrase}<|end|>\\n<|assistant|>\\n{tone}<|end|>"
      },
      {
        "type": "String",
        "label": "Corpus strategy:",
        "info": "Do you want to join the samples or process them one by one.",
        "replaceToken": "join",
        "defaultValue": "join",
        "optionValues": [
          "line-by-line",
          "join"
        ]
      },
      {
        "type": "Integer",
        "label": "Source max length:",
        "info": "Max numbers of tokens per traning sample.",
        "replaceToken": "1024",
        "defaultValue": 1024
      },
      {
        "type": "Boolean",
        "label": "Pad to max length:",
        "info": "Add PAD token to the training sample until the max number of tokens.",
        "replaceToken": "false",
        "defaultValue": false
      }
    ]
  },
  {
    "groupId": "fine_tune",
    "title": "Fine tune settings",
    "fields": [
      {
        "type": "String",
        "label": "Compute dtype:",
        "info": "Data type for model weights and adapter weights.",
        "learnMore": "hello world",
        "replaceToken": "bfloat16",
        "optionValues": [
          "bfloat16",
          "float16"
        ],
        "defaultValue": "bfloat16"
      },
      {
        "type": "String",
        "label": "Quant type:",
        "info": "Quantization data type to use. Should be one of fp4 or nf4.",
        "replaceToken": "nf4",
        "optionValues": [
          "nf4",
          "fp4"
        ],
        "defaultValue": "nf4",
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter quant_type?"
      },
      {
        "type": "Boolean",
        "label": "Double quant:",
        "info": "Whether to use nested quantization where the quantization constants from the first quantization are quantized again.",
        "replaceToken": "true",
        "defaultValue": true,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter double_quant?"
      },
      {
        "type": "Integer",
        "label": "Lora r:",
        "info": "Lora attention dimension.",
        "replaceToken": "64",
        "defaultValue": 64,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter lora_r?"
      },
      {
        "type": "Integer",
        "label": "Lora alpha:",
        "info": "The alpha parameter for Lora scaling",
        "replaceToken": "64",
        "defaultValue": 64,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter lora_alpha?"
      },
      {
        "type": "Number",
        "label": "Lora dropout:",
        "info": "The dropout probability for Lora layers",
        "replaceToken": "0.1",
        "defaultValue": 0.1,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter lora_dropout?"
      },
      {
        "type": "Integer",
        "label": "Eval dataset size:",
        "info": "Size of the validation dataset, a number or 0-1 percentage.",
        "replaceToken": "0.3",
        "defaultValue": 0.3,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter eval_dataset_size?"
      },
      {
        "type": "Integer",
        "label": "Seed:",
        "info": "Random seed for initialization.",
        "replaceToken": "0",
        "defaultValue": 0,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter training_args_seed?"
      },
      {
        "type": "Integer",
        "label": "Data seed:",
        "info": "Random seed to be used with data samplers.",
        "replaceToken": "42",
        "defaultValue": 42,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter training_args_data_seed?"
      },
      {
        "type": "Integer",
        "label": "Per device train batch size:",
        "info": "The batch size per GPU for training.",
        "replaceToken": "1",
        "defaultValue": 1,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter per_device_train_batch_size?"
      },
      {
        "type": "Integer",
        "label": "Per device eval batch size:",
        "info": "The batch size per GPU for evaluation.",
        "replaceToken": "1",
        "defaultValue": 1,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter per_device_eval_batch_size?"
      },
      {
        "type": "Integer",
        "label": "Gradient accumulation steps:",
        "info": "Number of updates steps to accumulate the gradients for, before performing a backward/update pass",
        "replaceToken": "4",
        "defaultValue": 4,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter gradient_accumulation_steps?"
      },
      {
        "type": "Boolean",
        "label": "Enable gradient checkpointing:",
        "info": "Use gradient checkpointing. Recommended to save the memory.",
        "replaceToken": "true",
        "defaultValue": true,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter gradient_checkpointing?"
      },
      {
        "type": "Number",
        "label": "Learning rate:",
        "info": "The initial learning rate for AdamW",
        "replaceToken": "0.0001",
        "defaultValue": 0.0001,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter learning_rate?"
      },
      {
        "type": "Integer",
        "label": "Number of epochs:",
        "info": "How many complete passes the model will make over the entire training dataset.",
        "replaceToken": "3",
        "defaultValue": 3,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter num_train_epochs?"
      },
      {
        "type": "Integer",
        "label": "Max steps:",
        "info": "Training will be stopped when this number of steps is reached, regardless of the number of epochs.",
        "replaceToken": "1200",
        "defaultValue": 1200,
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter max_steps?"
      },
      {
        "type": "String",
        "label": "Checkpoint output dir",
        "info": "Directory to save the checkpoints.",
        "replaceToken": "models/checkpoints",
        "defaultValue": "models/checkpoints",
        "learnMore": "Can you tell me more about the Hugging Face trainer parameter output_dir?"
      }
    ]
  }
]